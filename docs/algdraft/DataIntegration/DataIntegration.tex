\documentclass[conference]{IEEEtran}

\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi

\usepackage{algorithm}
\usepackage{algorithmic}
 \renewcommand\floatpagefraction{0.99}
 \renewcommand\topfraction{0.99}
 \renewcommand\bottomfraction{0.99}
 \renewcommand\textfraction{.05}
 \setcounter{totalnumber}{5}

\newtheorem{example}{\bf Example}[section]
\newtheorem{definition}{\bf Definition}[section]
\newcommand{\from}[2]{{\bf[{\sc from #1:} #2]}}

\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Querying Integrated Scientific Observation and Measurement Data}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Author1}
\IEEEauthorblockA{School of Electrical and\\Computer Engineering\\
Georgia Institute of Technology\\
Atlanta, Georgia 30332--0250\\
Email: http://www.michaelshell.org/contact.html}
\and
\IEEEauthorblockN{Author2}
\IEEEauthorblockA{Twentieth Century Fox\\
Springfield, USA\\
Email: homer@thesimpsons.com}
\and
\IEEEauthorblockN{Author3}
\IEEEauthorblockA{Starfleet Academy\\
San Francisco, California 96678-2391\\
Telephone: (800) 555--1212\\
Fax: (888) 555--1212}}

\maketitle


\begin{abstract}
%\boldmath
The abstract goes here.
\end{abstract}

% no keywords

\section{Introduction}\label{sec:intro}
In this work, we study the query processing over scientific
observation and measurement data using OBOE
model\cite{DBLP:conf/er/BowersMS08}. OBOE model is a conceptual model
used to interpret observation and measurement data. 

\subsection{Background}

%Application background
In many scientific domains (e.g., ecology, hydrology, earth science,
geology), people collect observational data. Such data
record the observed value of some real world entity at some specific
place and time. E.g., ecologists studying relationship between the 
growth pattern and the treatments often need to record the tree
heights. The collected data reflect the fact the tree height of a
specific tree is 30.1in on May 1, 2009 and 30.3in on May 1, 2010. 

%Characteristics of scientific observational data: non-normalized
Almost all such scientific data do not follow database higher normal
forms. Generally, scientists have their way in interpreting their
data, but they are not ready for any normalization process. 
For example, Table \ref{tb:dataset} is a simplified but typical dataset collected by
a scientist who study the growth pattern of trees. 
Obviously, the ``plt'' of the first two rows is the same place, and
the ``plt'' of the last two rows is the same. 
Here, their area information is redundant. 
In the real application, many columns have redundant information. 

%HP: this one has the coordinates, it's troublesome to explain. 
%% \begin{table}[htb]
%% \begin{center}
%% \begin{tabular}{|l|l|l|l|l|}
%% \hline
%% code & no & ht & plt & area\\\hline
%% piru & 1 & 35.8 & $(34^{\circ}8'3N,118^{\circ}14'37W)$ & 4.0\\\hline
%% piru & 2 & 36.2 & $(34^{\circ}8'3N,118^{\circ}14'37W)$ & 4.0\\\hline
%% piru & 1 & 25.7 & $(36^{\circ}10'30N,115^{\circ}8'11W)$ & 3.0 \\\hline
%% %abba & 1 & 15.6 & $(36^{\circ}10'30N,115^{\circ}8'11W)$ & 3.0\\\hline
%% capo & 1 & 15.6 & $(36^{\circ}10'30N,115^{\circ}8'11W)$ & 3.0\\\hline
%% \end{tabular}
%% \end{center}
%% \caption{Dataset}
%% \label{tb:dataset}
%% \end{table}


\begin{table}[htb]
\begin{center}
\begin{tabular}{|l|l|l|l|l|}
\hline
code & no & ht & plt & area\\\hline
piru & 1 & 35.8 & California & 4.0\\\hline
piru & 2 & 36.2 & California & 4.0\\\hline
piru & 1 & 25.7 & Oregon & 3.0 \\\hline
%capo & 1 & 7.8 & Oregon & 3.0\\\hline
Oriental poppy& 1 & 7.8 & Oregon & 3.0\\\hline 
\end{tabular}
\end{center}
\caption{Dataset}
\label{tb:dataset}
\end{table}
%HP: California poppy info
%Oregon iris: http://en.wikipedia.org/wiki/List_of_native_Oregon_plants
%http://en.wikipedia.org/wiki/California_poppy


%Introduce major concepts
In scientific domains where people collect observation and measurement
data, there are several commonly used and widely recognized canonical
concepts(\cite{oboe, om}). 
In this paper, we refer these concepts as OM concepts. 
The canonical concepts include {\em observation}, {\em measurement},
{\em characteristic}, {\em standard}, {\em protocol} or ({\em procedure}). 
For example, {\bf add an example to illustrate these concepts. }


%Introduce annotation, Motivation to use annotation
Generally, every scientific dataset goes into the data repository with
some metadata, e.g., Dublin core metadata\cite{***}, Darwin core metadata\cite{***}. 
However, all these metadata are at the dataset level, they did not
provide enough information for the data {\em content} inside the
dataset. 
To better make use of the data content in the repository, more systems
are embracing the ideas of having metadata on the data content. 
E.g., Some systems \cite{tdar} provides a mechanism to collect the
column/attribute level metadata, some system \cite{semtools} uses
{\em annotation} to add more semantic information to the data
content. In this work, we follow the terminology in \cite{semtools} and
use the term {\em annotation} to distinguish the 
metadata on the data content from those on data objects at a coarser
granularity. 
%How to represent the annotation and the symbols used
We propose tools for scientists to provide annotations to scientific
observational data. 
\from{HP}{Put a screen-dump of annotation.}


%Queries to such data and challenges to answer such queries.
The internal data structure of such scientific data repository is
generally unknown to a user who wants to pose a query to such scientific data
repository and get some useful information. 
So, it is unrealistic for a him/her to formulate a query based on the 
underlying data structure of the data.  
The easiest query they can pose to such data repository are keyword-query. 
Such keyword style query works well for the dataset metadata
(e.g., contributor information, dataset description, etc) using the
current Information Retrieval (IR) techniques. However, it
is far from enough to be used to search the data content because the
data content need to be interpreted with semantics. 
It is important in the scientific domain to have typical
kinds of queries. One fact we can use is that the domain
scientists know well the widely used OM concepts as discussed above. 
So, naturally, when searching such scientific data, they can provide
the concept information to restrain their queries and to find data sets
related to such OM terminologies. 
Given the dataset in Table \ref{tb:dataset}. 
People may ask the following observation and measurement (OM) queries. 

\begin{example}\label{eg:query}
Simple and summarization queries: 
\begin{itemize}
\item $Q_1$: Give me the data sets that contain species ``Picea rubens'' observations.
%$Q_2$: Give me the data sets that have measurements on ``area''  characteristics. 
\item $Q_2$: Give me the data sets that contain species ``Picea rubens''
  observations in ``California''. 
\item $Q_3$: Give me the data sets that contain at least five distinct
  ``Picea rubens'' observations.
\item $Q_4$: Give me the data sets that have trees with average ``height''
  than 20.0 in ``California''. 
% Shawn: an example on summarize one measure with respect to another.
% This could take two forms: one where the context forms the groups
% (like by year), and another where the two measurements are within the
% same context (like finding correlations).
\end{itemize}
\end{example}
\from{HP}{Challenges to answer such queries: uniqueness}

\from{HP}{Current data integration effort}

\from{HP}{Our effort in querying observational data: introduce OBOE}

\from{HP}{Need re-organization. The description in the
  following several sections may be moved to here later.}

\subsection{Contribution and paper organization}
Contributions of this work:
\begin{itemize}
\item We formulate a canonical set of queries over observation and
  measurement scientific data repository. Such formal queries can
  formalize most OM concepts related searches. 
\item We propose three methods to evaluate such OM
  queries. \from{HP}{Elaborate the three methods.}
\end{itemize}

This paper is organized as follows. 
Section \ref{sec:relatedwork} reviews works that are related to this
research. Section \ref{sec:dataquery} formalizes the data model and the
queries that people are interested to ask.  

\section{Related work}\label{sec:relatedwork}

\from{HP}{This will come after the real problem definition and the
  solution. The description in the following several sections may be
  moved to here later.}

\section{Data model, annotation and query}\label{sec:dataquery}




In this section, we first illustrate the data model. Then, we
formalize the queries that scientists in this domain tend to ask. 

\subsection{Data model}\label{sec:datamodel}

%Data model: Data, attribute, data value set
When a scientist contributes data into an integrated data repository,
a widely accepted way is to convert each dataset to a data
table\cite{tdar} or treated as a separate object entity\cite{knb}. 
{\bf (HP: is it really widely used? any other system uses this
  way?. Add more citations here.)}
In using this method, the database contains metadata of each
dataset and the definition of the data table (e.g., attribute/column
name, attribute type, etc). 


%HP: 
%An alternative way to organize the data is to store them in one big
%data table with three columns data\_file, attribute\_name,
%attribute\_value. The problem with this structure is that the
%attribute\_value are different types.
In our work, we focus on querying this kind of data repository (or
databases). To formalize the scenario, we use $D$ to denote the set of data
tables in the data repository and $d$ to refer to a specific data
table. Each data table $d$ contains metadata about the attribute
definition $Attr_{d}$. Sometimes, we also use {\em column} to refer to an
attribute. 
Given one data table $d$, an attribute $attr_i \in Attr_{d}$ or column index $i$, 
$d[attr_i]$ or $d[i]$ represents the set of values for the attribute
$attr_i$ or for the $i$-th column.
%HP: Implementation detail (no need to put it in the paper): 
%When we put the data to data tables, we add a unique record id for
%each row in the data. This is used to get the unique record id. 

\subsection{Annotation}\label{sec:annotation}



%What kinds of annotation information is needed. 
We use $A$ to denote the annotation of one dataset. 
Internally, we keep the following information for the
annotation. 

For a data table $d$ with annotation $A$, the system keeps the
corresponding information between them in $AD$ tables. 
Besides it, we also have four main concepts to describe: 
observation type (OT), measurement type (MT), and
context type (CT), and the mapping (Map) from the measurement type to
resource attributes.  
So, the annotation contains the following information. 

\begin{itemize}
\item $AD$ = $\{(d_{id}, A_{id}, d_{meta})\}$ to keep the information
  of data sets $d_{id}$-s and their related annotations
  $A_{id}$. Here, $d_{meta}$ is an abstract attribute for all the
  other metadata of $d_{id}$. 
\item $OT$ = $\{(\underline{A_{id},ot_{id}}, et, isDistinct)\}$ to
  describe an observation type. It denotes on which
  entity type (object in the real world) the observation is made. 
Very often, more than one observation can be made on one entity. Thus,{\em
  isDistinct} is used to denote whether the same value of key
measurements of an obbservation types can uniquely identify one
observation or not. 
\item $MT$ = $\{(\underline{A_{id}, mt_{id}}, ot_{id},isKey,
  Cha, \cdots)\}$. Generally, $MT$ contains information about
  characteristic ($Cha$), Standard, Protocol and Precision. We do not include them
  here to make the description clearer. Here, {\em isKey} is used to denote
  whether one measurement type is the key measurement for the
  observation type $OT_{id}$ or not. 
\item $CT$ = $\{(\underline{A_{id}, ct_{id}}, ot_{id}, cot_{id}, Rel,
  isIdentify)\}$ where $cot$ represents the context observation
  type. 
\item $Map$ = $\{(\underline{A_{id},mt_{id}, attr_i, mapCond, mapVal},
  Val\}$. This structure denotes the correspondences between an
  measurement type ($mt_{id}$ and an attribute $attr_i$ in an dataset
  $d_{id}$ for a given condition $mapCond$. 
\end{itemize}

We use the following example to illustrate the concepts in the
annotation. 



\begin{example}
$OT$ = \{($A_1, OT_1$, tree, false),($A_1, OT_2$, GeoSpot, true) \}
  denotes that annotation $A_1$ are for two observation types. One
  type $OT_1$ is on real world entity ``tree'' and the values of its key measurements
  do not uniquely identify a distinct observation. The other type
  $OT_2$ is for real world entity ``GeoSpot'' (i.e., geospatial
  location) and its key measurement types can identify it's unique
  observations. \from{HP}{Introduce key measurements before this.}

$MT$ =\{($A_1, MT_1, OT_1$, Species, true), 
($A_1, MT_2, OT_1$, SpecNo, true), 
($A_1, MT_3, OT_1$, Height, false),
($A_1, MT_4, OT_2$, Plot\_State, true), 
($A_1, MT_5, OT_2$, Plot\_Area, false)\} represents that $OT_1$
(for ``tree'') has three measurement types ($MT_1, MT_2$, $MT_3$) for characteristics
``Species'', ``SpecNo'', and ``Height''. The fist two measurement
  types together form the key measurement type for $OT_1$. 
$OT_2$ (for ``GeoSpot'') has one key measurement type $MT_4$ for
  characteristic ``Plot\_State'' and another measurement type $MT_5$
  for characteristic ``Plot\_Area''. 

$CT$ = \{($A_1$,$OT_1$, $OT_2$, within, true)\}. It shows that
observation of a {\em tree} is within the context of a geo-spatial
location. And this context is used to identify the uniqueness of the
observation. E.g., a tree with species name ``piru'' and species no
$1$ in California
%$(34^{\circ}8'3N,118^{\circ}14'37W)$ (Los Angeles in California) 
is different from a tree with 
the same species name ``piru'' at Oregon. 
%location $36^{\circ}10'30N,115^{\circ}8'11W$ (Las Vegas in
%California). 

%HP coordinates material: 
%http://www.traveljournals.net/explore/united_states/map/u1662328/los_angeles.html
%http://en.wikipedia.org/wiki/Las_Vegas,_Nevada

$Map$ = \{($A_1$, $MT_1$, ``code'', ``eq `piru''', ``Picea rubens''),
%($A_1$, $MT_1$, ``code'', ``eq `abba''', ``Abies balsamea''),
%($A_1$, $MT_1$, ``code'', ``eq `capo''', ``California poppy''),
($A_1$, $MT_2$,``no'', null,), 
($A_1$, $MT_3$, ``plt'', null,), 
($A_1$, $MT_4$,``area'', null,\}. 
The first mapping rules maps ``code''
attribute to the measurement type $MT_1$ (for ``Species''
characteristic) and change the value to ``Picea rubens'' if the code
is ``piru''. The meaning of the other mapping rules are very
obvious here, so we skip the details. 
\end{example}


\subsection{Observation and measurement (OM) query}
Above we defined the data model and the annotation. In this
sub-section, we formalize the queries that scientists are interested
in. We denote the queries on the observational data as {\em Observation
and measurement (OM) query}. 

As discussed in Section \ref{sec:intro}, it is generally impossible for a
scientist to formulate an OM query using the internal data structure
of a dataset because such data structures differ from contributors to
contributors. More realistically, they can pose queries
(Example \ref{eg:query}) related to key OM concepts, e.g., {\em
  observation, measurement,characteristic, and standard}, and these
OM concepts satisfy given keyword and context conditions. 

\begin{definition}[Basic OM query]\label{def:basic_omq}
A basic observation and measurement query is defined as 
\[Q::={\tt OMconcept:}\langle{\tt cond}\rangle}\]
Here, 
\begin{itemize}
\item {\tt OMconcept} refers to one of the major OM terminologies. 
\item 
$\langle${\tt cond}$\rangle$ is in the form of 
{\tt f([distinct entity.]measurement) op value} 
where {\tt op} is a basic operator from $\{=, \neq, >, <\}$ 
and {\tt f} is an
aggregation function from $\{sum, avg, count, min, max\}$. 
{\tt distinct} and {\tt entity} are optional. 
\end{itemize}
\from{HP}{The symbol fonts are a little bit messy...need to
  distinguish between the keywords and variables.}
\end{definition}

\begin{definition}[Result of OM query]\label{def:qresult}
The result of a query $Q$ is a set of data objects (e.g., data tables) 
\{$d|d\in D \wedge d~satisfies~\langle ${\tt cond} $\rangle$\}. 
For each of such result $d$, we use $d~s.t.~Q$ to denote that
an data object $d$ satisfies the query. 
\end{definition}

Based on the different $\langle${\tt cond}$\rangle$ definitions,
``$d~satisfies~\langle${\tt cond}$\rangle$''
is translated differently. 
E.g., if $\langle${\tt cond}$\rangle$ is defined that the value of ``{\em area}'' need to be
smaller than $3.0$, then, ``$d~satisfies~{\tt cond}$'' is translated to
``$dv<3.0|dv\in d[area]$''.
 
Definition \ref{def:basic_omq} can formulate queries on
one specific observation and measurement. 
In real application, we need to consider the context relationship. 
\from{HP}{E.g., etc.}
So, we generalize the basic OM query to contextualized OM query as
follows. 

\begin{definition}[Contextualized OM query]\label{def:context_omq} A
  contextualized OM query is defined as:
\[CQ ::=Q_i \wedge {\tt context}(Q_i.{\tt OMconcept}, Q_j.{\tt
  OMconcept})\wedge Q_j\]
Here, $Q_i, Q_j$ are basic queries.
\end{definition}

For example, the queries in Example \ref{eg:query} can be formalized
as the following formal OM queries. 

%\begin{example}
\begin{itemize}
\item $Q_1$ = $Observation: \langle Species='Picea~rubens'\rangle$
\item $Q_2$ = $Observation_1: \langle Species='Picea~rubens'\rangle$\\
  $\wedge IN(Observation_1, Observation_2$) \\
$\wedge Observation_2: \langle Meas_{unknown}=`California'\rangle$
\item $Q_3$ = $Observation: \langle Species='Picea~rubens'$\\
$\wedge count(distinct~Species)\geq 5\rangle$
\item $Q_4$ = $Observation_1: \langle avg(distinct~tree.height)\geq 20.0 \rangle$ 
$\wedge IN(Observation_1, Observation_2)$\\
$\wedge Observation_2: \langle State='California'\rangle$\\
%Give me the data sets that have trees with average ``height''
%  than 20.0 in ``California''
\end{itemize}

%\end{example}


%\from{HP}{Add experiement: show the error rate (e.g., precision, recall, (or
%  directly $F_1$) of this method.? not needed?}

\section{Querying annotated and integrated OM data}

In this section, we propose several methods that can be used to
answer OM queries over scientific observational data with
annotations. 

%\subsection{Naive method}\label{sec:naive}
A very direct way to search such data is to extract all the content in
the data cells and index them. This way the system may help answer
very simple queries with the help of some thesaurus. 
For example, for $Q_1$ in Example \ref{eg:query}, as long as we can
translate the abbreviation ``piru'' in the dataset to ``Picea rubens''
based on some predefined thesaurus, we can find the results. 
However, even for this kind of simple query, if we want to find
observation of ``California poppy'', an approximate match may return
the dataset in Table \ref{tb:dataset} as a result because it contains
both {\em California} and {\em Poppy}.
If the search problem caused by the compound words can be alleviated using some existing
techniques \cite{***}, %citation on compound word querying. 
it is still almost impossible to directly use such IR-style system to answer a query
in the form of $Q_3$ and $Q_4$. 
This naive method cannot be directly used answer the desired queries. It is because it
fails to catch the semantics of the context and uniqueness of observations in the data. 
In what follows, we utilize the annotation information to get
more semantic support, and provide new strategies to answer the
queries. 

As we analyzed in Section \ref{sec:relatedwork}, there are two extrems
in querying integrated data. 
One is to rewrite the original query to a series of new queries over
the data; the other is to materialize the data to a consistent data
model and then answer the query over the materialized database. 
In what follows we work from these two directions to leverage the
semantic information in answering such queries. 

\subsection{Query rewriting}\label{sec:queryrewrite}

As described in Section \ref{sec:dataquery}, 
an OM query is represented using 
OM concept terminologies such as observation, 
measurement, characteristic, etc. 
To answer such queries from the original data model (i.e., dataset 
metadata and translated data tables), 
we need to {\em rewrite} the OM query over the real data tables. 
In what follows, we first sketch the re-writing process. 
Then, we detail the procedure in using the data model and structures. 
Finally, we include the process for the more complicated
cases (e.g., with distinct, aggregate). 

%Framework of query rewriting
Roughly speaking, the query rewriting consists of two steps:
\begin{itemize}
\item From the given query, search the database metadata and
  annotation information to find the relevant data tables and
  attributes that need to be used to answer the given query. 
\item Translate the given OM query to queries over the relevant data
  tables. 
\end{itemize}

\from{HP}{todo:put a figure here to illustrate the steps}. 

%Elaborate the first step
The first step is to map the OM concepts in the query to the real data
structure. 
With the annotation structures $OT$, $CT$, and $MT$, any given OM
concepts can be linked to a measurement type $mt_{id}$. 
Then, the annotation structure $Map$ can be used to bridge OM concepts and data sets. 
Utilizing $Map$, we can find the attributes $attr_i$ and the
annotation $A_{id}$).
E.g., when the given concept is {\em measurement}, we can directly get
its related attribute names and annotation id $A_{id}$. 
In case that the given OM concept is a non-measurement concept, we can use
other annotation structures to figure out the measurementt types. 
E.g., if the OM concept is {\em characteristic} ``Species'', we can use
$MT$ to get the measurement type id $mt_{id}$. 
After we get $A_{id}$, we can quickly find the dataset id $d_{id}$
using $AD$ metadata table (Section \ref{sec:annotation}). 
Then, we get the relevant data tables and the needed attributes. 

%Elaborate the second step
Let $D_{cand}$ be the set of relevant (or candidate) data tables and $d_{a_1} \cdots d_{a_m}$
are the related attributes for table $d\in D_{cand}$. 
The second step translates the original OM query to SQL queries over the data tables.  

In particular, for each candidate data table $d$,  
the translation process works in the following rules. 

\begin{itemize}
\item The SELECT clause always get the distinct $d_{id}$ and/or
  record id $r_{id}$ (when it is needed);
\item The FROM clause has table $d \in D_{cand}$;
\item The WHERE clause contains all the function $f(\cdot)$ in the OM
  query;
\item When there is distinct constraint on entity or observation, the
  GROUP BY clause contains of all the attributes corresponding to the
  {\em key measurement types} of the entity or observation. we detail
  all process of getting the key measurement types of an observation
  later. 
\item The aggregation requirement in $f(\cdot)$ is translated to
  HAVING clause. 
\end{itemize}

Based on these rules, an OM query can be translated to the following
SQL scripts. 

\vspace{0.1in}
{\tt 
\begin{tabular}{l} 
SELECT DISTINCT $d_{id}$\\
FROM $d$\\
WHERE $f(d_{a_1} \cdots d_{a_m}) = true$\\
$[$GROUP BY {\em distinct requirement}$]$\\
$[$HAVING {\em aggregation condition}$]$;
\end{tabular}
}
\vspace{0.1in}

The above describes the process for the OM query. 
In real application, people ask queries with distinct
observation or entity constraints. Also, people ask queries about
different observatitons using context. 
The following elaborate the details in processing these two cases. 

%In detail,  how to deal with the distinct constraints.
When a query with distinct constraints, e.g., find data sets with {\em distinct} observations or
entities. To deal with this case, 
we need to be able to figure out what distinguishes one observation
from another. Here, one observation type's key measurement types can
play this role well. 
When an observation type is denoted with {\em distinct yes} and some
of its measurement types are denoted with {\em key yes}, 
the values of the measurements on the key measurement types can
uniquely distinguish one observation from the other. 
To implement this, in SQL, we can perform ``group by'' operations on
the key measurement types of the observations. 

%In detail, how to deal with context
When the given OM query has context, we need to consider two cases. 
In the first case the context is not {\em identifying} to its
observation types, i.e., the context value
does not affect the uniqueness of one observation, this can be
processed as the basic way. 
When the context is denoted with {\em identifying yes}, it means the
identity of one observation also depend on the contextual
observation. 
In this case, we need to figure out the all the key measurement types
of one observation, then the ``GROUP BY'' operation should be on all
these key measurement types. 
\from{HP}{Put an example here.}
In this case, there is no need to change the SQL scripts.
the only change are the relevant attribute set $d_{a_1} \cdots
d_{a_m}$, which corresponds to not only the measurement types that
directly related to the observation, but also the measurement types
that are in the identifying context chain of the observation. 

\from{HP}{Put a specific routine to get key measurements of
  observation and/or entity.}


\begin{example}\label{eg:query_reqerite_q1}
{\bf TODO: refine this example} 
Take $Q_1$ ($Observation: \langle Species='Picea~rubens'\rangle$) as
example. 
The {\tt OMconcept} is ``observation'' and {\tt cond} is ``{\em species = `Picea rubens'}''; 

From the annotation $MT$, we can find the measurement type
$m_3$ with the characteristic {\em species}. 
From the mapping $Map$, we further find that the attribute {\em spp} that the
measurement type $m_3$ is mapped to. 

The second step is to find the data sets which really have this value. 
For this one, we find the data table, and do a selection on the table
content. 

\vspace{0.1in}
{\tt 
\begin{tabular}{l} 
SELECT DISTINCT $d_{id}$\\
FROM $d$\\
WHERE $spp = 'piru'$
\end{tabular}
}
\vspace{0.1in}

\end{example}

\begin{example}
Take $Q_3$ ($Observation:$\\
$\langle Species='Picea~rubens'$$\wedge count(distinct~Species)\geq
5\rangle$) as an example. 

\from{HP}{Refine\\
For the first step, we find the data tables that contain the needed concepts. 
In each table, we need to figure out the distinct observations. 
From $m_i$ $obstype_i$, all the other measurements that are of
$obstype_i$. 
Group by the key measurements of $obstype_i$ if distinct yes.
If this observation type does not have any context, then the key
measurements are all the measurements directly defined under this
observatioin type. Otherwise, i.e., this observation type has context,
then the key measurements are all the measurements in the context
chain. }

\vspace{0.1in}
{\tt 
\begin{tabular}{l} 
SELECT DISTINCT $d_{id}$\\
FROM $d$\\
WHERE $spp = 'piru'$\\
GROUP BY $d_{id}$, $spp$\\
HAVING count($d_{id}$,$spp$) $\geq 5$\\
\end{tabular}
}
\vspace{0.1in}

\end{example}

%Analysis of this method. 
{\bf Cost analysis:} 
From the above description, we can tell that the computation cost is to search the different data
tables. This way, for each candidate data table, we need to send an
SQL query to the server for evaluation purpose.
If the number of candidate data tables are small. This method should
work well. However, when we have a lot of candidate data tables, the
efficiency may be affected. 
In what follows, we introduce another strategy, which logically merge
the data content in different tables and perform queries ober the
materialized database. 

\subsection{Querying materialized database}\label{sec:matdb}

The previous section shows the method to rewrite a given query. 
However, as we analyzed, the computation cost may be very high when
there are many candidate data tables. 
In this section, we propose another strategy to answer the given OM
query by making use of the existing optimization strategies of
current DBMS. 

%rough idea of this strategy
In this strategy, we do not directly work on the original data table
$D$. On the other hand, we {\em materialize} the original data-sets to
centralized concept tables with instances of entities, observations, measurements
and contexts. Such concept tables are called core OBOE tables, and denoted as
$OBOE.*$. 
Then, the query process works on the materialized databases (i.e., the
conceptual data tables). 

%structure of this sub-section
In what follows, we first describe the structure of the core
conceptual tables and present our algorithm to materialize the data into such
concept instance tables in Section \ref{sec:materialilzedb}. Our
algorithm considers all the distinct and context constraints. 
Then, Section \ref{sec:query_materialilzedb} provides the detailed
process of performing queries over materialized database. 

\subsubsection{Materialize data}\label{sec:materialilzedb}

%Structure of conceptual instances
In particular, we have the following concept instance tables. 
\begin{itemize}
%\item $EI$ = $\{(\underline{ei_{id}}, et_{id})\}$ for all the entity instances;
\item $OI$ = $\{(\underline{oi_{id}}, ot_{id}, ei_{id})\}$ keeps
  all the observation instances where $ot_{id}$ is used to link to the
  annotation information in $OT$; 
\item $MI$ = $\{(\underline{mi_{id}}, oi_{id}, mt_{id},
  mVal)\}$ for all the measurement instances where $mt_{id}$ is used to link to the
  annotation information in $MT$; 
\item $CI =\{(\underline{oi_{id},coi_{id},ct_{id}})\}$ for
  all the context instances where $ct_{id}$ is used to link to the
  annotation information in $CT$. 
\end{itemize}

\from{HP}{TODO: refine the writing in MaterializeDB and move them here.}

\subsubsection{Querying materialized database}\label{sec:query_materialilzedb}

Once the data are materialized using the annotation constraints, we
can perform the OM query over them. 
%In what follows, we describe how to use the materialized data to answer the query. 

\from{HP}{TODO:Formalize the translation of operators in the OM
  query}. 

When the given query is a basic OM query, i.e., there is not context
in the query. 
Then, we can form a template query as the following;

\begin{figure}[htb]
{\tt
\begin{tabular}{l}
SELECT $[$DISTINCT$]$ $AD.d_{id}$\\
FROM $AD, MI~as~mi, MT~as~mt[$, {\em other tables}$]$\\
$[$WHERE    {\em table join condition, \\
$\qquad\qquad$ AND selection condition}$]$,\\
$[$GROUP BY {\em distinct requirement} $]$\\
$[$HAVING   {\em aggregation condition} $]$;
\end{tabular}
}
\caption{SQL template to answer OM using materialized DB}
\label{fig:sql_matdb_basic_omq}
\end{figure}

In particular, 

\vspace{0.1in}
\begin{tabular}{l}
$table~join~condition=$\\
%$\qquad (mi.oi_{id}=ci.oi_{id})~AND~(cmi.oi_{id}=ci.coi_{id})~AND$\\
$\qquad (mi.mt_{id}=mt.mt_{id})~AND~(mt.A_{id}=AD.A_{id})$
\end{tabular}
\vspace{0.1in}

For the very basic query (e.g., $Q_1$ in Example \ref{eg:query}), the
SQL generally need only the first three clauses. 
If the query has some restriction on the aggregated result, the {\tt
  GROUP BY} and {\tt HAVING} clauses to deal with it. 

We use $Q_1$ and $Q_3$ to illustrate the query on the materialized
database. 
can be answered using the above
template. 
Example \ref{eg:query_reqerite_q1} shows how to deal with $Q_1$ using
the query rewriting method. 

\begin{example} \label{eg:materialize_db_q1}
Using the  materialized database,  we just need to search the MI table
with the condition that {\em mVal=``Picea rubens''}.

\vspace{0.1in}
{\tt 
\begin{tabular}{l}
SELECT DISTINCT $AD.d_{id}$\\
FROM $AD, MI~as~mi, MT~as~mt$\\ 
WHERE $mt.Cha='Species'$ \\
$\qquad\quad$ AND $mi.mVal = `Picea~rubens'$\\
$\qquad\quad$ AND $mi.mt_{id}=mt.mt_{id}$\\
$\qquad\quad$ AND $mi.A_{id}=AD.A_{id}$; 
%\#Join the MI and MT tables
\end{tabular}
}
\vspace{0.1in}

For $Q_3$, which asks for data sets that contain at
least five distinct ``Picea rubens'' observations.
The SQL query can be written as: 

\vspace{0.1in}
{\tt 
\begin{tabular}{l}
SELECT distinct $AD.d_{id}$\\
FROM $AD, MI~as~mi, MT~as~mt$\\
WHERE $mt.Cha='Species'$ \\
$\qquad\quad$ AND $mi.mVal = `Picea~rubens'$\\
$\qquad\quad$ AND $mi.mt_{id}=mt.mt_{id}$\\
$\qquad\quad$ AND $mt.A_{id}=AD.A_{id}$\\
GROUP BY $d_{id},oi_{id}$\\
HAVING COUNT(*)$>$5; 
}
\end{tabular}
}
\vspace{0.1in}
\end{example}

For this kind of query, the computation cost is the selection cost of the
measurement instance (MI) table. 
Compared with the query rewriting strategy, which need to pose the
query over multiple data tables, this query should answer the queries
more efficiently. 

Figure \ref{fig:sql_matdb_basic_omq} shows the SQL template to process
the basic OM query without context. In case the OM query has context,
we need to add the context into consideration. 

\begin{enumerate}
\item The first step is similar to that in the basic OM query
  processing. Besides this, we need to figure out what are the concept
  obserbationi types of the needed observations.  
\item \label{step:singlesql} Form an SQL for the observation and every of its context
  observations. 
\item Intersect all the SQLs from Step \ref{step:singlesql}). 
\end{enumerate}


\begin{figure}[htb]
{\tt
\begin{tabular}{l}
SELECT $[$DISTINCT$]$ $AD.d_{id}$\\
FROM $AD, CI~as~ci,MI~as~mi, MT~as~mt$\\
$\qquad MI~as~cmi, MT~as~cmt[,$ {\em other tables}$]$\\
$[$WHERE    {\em table join condition, \\
$\qquad\qquad$ AND selection condition}$]$,\\
$[$GROUP BY {\em distinct requirement} $]$\\
$[$HAVING   {\em aggregation condition} $]$;
\end{tabular}
}
\caption{SQL template to answer contextualized OM using materialized DB}
\label{fig:sql_matdb_context_omq}
\end{figure}

In this case, the table join condition is much more complex since we
need to use the context instance table $ci$ to connect the
observation and context observation table. 
In particular,

\vspace{0.1in}
{\tt 
\begin{tabular}{l}
$table~join~condition=$\\
$\qquad (mi.oi_{id}=ci.oi_{id})$ AND $(cmi.oi_{id}=ci.coi_{id})$ AND\\
$\qquad (mi.mt_{id}=mt.mt_{id})$ AND $(cmi.mt_{id}=cmt.mt_{id})$ AND\\
$\qquad (mt.A_{id}=AD.A_{id})$
\end{tabular}
}
\vspace{0.1in}

{\bf Execution cost analysis:} From the join condition, we can see that the expensive cost comes from
the join operation between the measurement instance, context
measurement instance, and context instance table. 
As we analyzed in Section \ref{sec:materialilzedb}, the two tables with
growing space are measurement instance table and context instance
table. 
 
{\bf Example:} When we are given contextualized query, e.g., $Q_2$, which asks for
the datasets that contain species ``Picea rubens'' observations in
``California''. 

In the first step, we get the requirement is on Characteristic
``Species'' with value ($mVal$) ``Picea rubens'' and observation has context {\em in}
another observation for ``State'' of value ``California''. 


%Using materializedDB, we can answer the query this way
%First, from the Characteristic ``Species'', we can get  --> mlabel, observation type 

%select mtype, olabel from measurement\_type  \\
%where chracteristic = 'Species';  \\
In the first step, we need to find the context type id $tmp\_ct\_id$
that satisfy the context relationship. 

{\tt 
\begin{tabular}{l}
SELECT $ct.ct_{id} as tmp\_ct_\id$\\
FROM OT as ot, OT as cot, CT as ct\\
WHERE $ct.ot_{id} = ot.ot_{id}$ AND \\
      $\qquad ct.cot_{id}= cot.ot_{id}$ AND \\
      $\qquad ct.Rel='IN'$ AND $ot.et='tree'$;
\end{tabular}
}

Then, the next step is to find the distinct data sets. 

\vspace{0.1in}
{\tt 
\begin{tabular}{l}
SELECT DISTINCT AD.d_{id}\\
FROM $AD, CI~as~ci, MI~as~mi, MT~as~mt,$ \\
$\quad\qquad MI~as~cmi, MT~as~cmt,$ \\
WHERE $(mi.oi_{id}=ci.oi_{id})$ AND $(cmi.oi_{id}=ci.coi_{id})$ AND\\
$\qquad (mi.mt_{id}=mt.mt_{id})$ AND $(cmi.mt_{id}=cmt.mt_{id})$ AND\\
$\qquad (mt.A_{id}=AD.A_{id})$\\
$\qquad$ AND $mi.mVal=`Picea rubens'$ \\
$\qquad$ AND $cmi.mVal='California'$\\
$\qquad$ AND $mt.Cha = 'Species'$\\
$\qquad$ AND $cmt.Cha=`State'$\\
$\qquad$ AND $ci.ct_{id} = tmp\_ct\_id)$\\
\end{tabular}
}
\vspace{0.1in}


%Use query rewriting, what I can do? 
%It's the same till to getting context\_olabel\_set. 

%Get the asked condition columns and the context columns, 

%select record\_id from data\_tables
%where condition column 1='value1' and (context column1 = 'context
%value' or context column2 = `context value', etc.);

Now let's think about the query $Q_4$ with aggregation and context
requirement. 
% Give me the data sets that have trees with average ``height''
%  than 20.0 in ``California''.
$Q_4 = Observation_1: \langle avg(distinct~tree.height)\geq 20.0 \rangle$ 
$\wedge IN(Observation_1, Observation_2)$\\
$\wedge Observation_2: \langle State='California'\rangle$


Also, in the first step, we discover the context type id $tmp\_ct\_id$
that satisfy the context relationship. 


\vspace{0.1in}
{\tt 
\begin{tabular}{l}
SELECT DISTINCT AD.d_{id} \\
FROM $AD, CI~as~ci, MI~as~mi, MI~as~cmi,$ \\
$\quad\qquad MT~as~mt, MT~as~cmt,$ \\
WHERE $(mi.oi_{id}=ci.oi_{id})$ AND $(cmi.oi_{id}=ci.coi_{id})$ AND\\
$\qquad (mi.mt_{id}=mt.mt_{id})$ AND $(cmi.mt_{id}=cmt.mt_{id})$ AND\\
$\qquad (mt.A_{id}=AD.A_{id})$\\
$\qquad$ AND $mt.Cha=`height'$\\
$\qquad$ AND $cmt.Cha=`State'$\\
$\qquad$ AND $cmi.mVal=`California'$\\
$\qquad$ AND $ci.ct_{id} = tmp\_ct\_id)$\\
GROUP BY $AD.d_{id}, oi_{id}$\\
HAVING $avg(mi.mVal)>5.0$;
\end{tabular}
}
\vspace{0.1in}

Note that, in the above example, there is only one context.
In the real application, there may be multiple context observations,
or even context chains. In this case, we need to get {\em all} the
context and get the intersection of the results. 


\subsection{Query partially materialized database}
As we analyzed in the first two sub-sections, 
the query-rewriting suffers the multiple queries posed on different
candidate dataset. The querying of materialized database suffers from
the multiple self-join operation of the measurement instance (MI)
table, which has the most amount of information. 

In this section, we propose to materialize only the measurement
instance and also put the measurement instance and context measurement
instances together in the same table to avoid the expensive
computation cost. 

\from{HP}{Let's see how this can work. }

\section{Experiments}

Synthetic data generator. 

Algorithm to materialize DB. 
Report the time and space. 

Synthetic query generator. 

Test algorithm to perform query over materiazed DB.
Test algorithm to perform query-rewriting over materiazed DB.

Test algorithm for half-materialized data.



\section{Conclusion}


\bibliographystyle{IEEEtranS}
\bibliography{IEEEabrv,DataIntegration}

\end{document}

