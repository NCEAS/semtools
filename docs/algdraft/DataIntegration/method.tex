\section{Querying annotated and integrated OM data}

In this section, we propose several methods that can be used to
answer OM queries over scientific observational data with
annotations.

%\subsection{Naive method}\label{sec:naive}
A very direct way to search such data is to extract all the content in
the data cells and index them. This way the system may help answer
very simple queries with the help of some thesaurus.
For example, for $Q_1$ in Example \ref{eg:query}, as long as we can
translate the abbreviation ``piru'' in the dataset to ``Picea rubens''
based on some predefined thesaurus, we can find the results.
However, even for this kind of simple query, if we want to find
observation of ``California poppy'', an approximate match may return
the dataset in Table \ref{tb:dataset} as a result because it contains
both {\em California} and {\em Poppy}.
If the search problem caused by the compound words can be alleviated using some existing
techniques \cite{***}, %citation on compound word querying.
it is still almost impossible to directly use such IR-style system to answer a query
in the form of $Q_3$ and $Q_4$.
This naive method cannot be directly used answer the desired queries. It is because it
fails to catch the semantics of the context and uniqueness of observations in the data.
In what follows, we utilize the annotation information to get
more semantic support, and provide new strategies to answer the
queries.

As we analyzed in Section \ref{sec:relatedwork}, there are two extremes
in querying integrated data.
One is to rewrite the original query to a series of new queries over
the data; the other is to materialize the data to a consistent data
model and then answer the query over the materialized database.
In what follows we work from these two directions to leverage the
semantic information in answering such queries.

\subsection{Query rewriting}\label{sec:queryrewrite}

As described in Section \ref{sec:dataquery},
an OM query is represented using
OM concept terminologies such as observation,
measurement, characteristic, etc.
To answer such queries from the original data model (i.e., dataset
metadata and translated data tables),
we need to {\em rewrite} the OM query over the real data tables.
In what follows, we first sketch the re-writing process.
Then, we detail the procedure in using the data model and structures.
Finally, we include the process for the more complicated
cases (e.g., with distinct, aggregate).

%Framework of query rewriting
Roughly speaking, the query rewriting consists of two steps:
\begin{itemize}
\item From the given query with entity, characteristic information, search the database metadata and
  annotation information to find the relevant data tables and
  attributes that need to be used to answer the given query.
\item Translate the given OM query to queries over the relevant data
  tables. To do this translation, we decompose an OM query to have several basic component operators. 
  \begin{itemize}
  \item Basic OM query with one entity type. While the characteristic condition may be conjunctive or disjunctive, it may also has aggregation. E.g., $A(Cha1>25.0 && Count(Cha)>3, Height>2.0)$
  \item Context OM chain refer to a set of queries having ``HasContext'' relationship. Obviously, these queries have different entity condition. E.g., $Ent1(...) --> Ent2(), Ent1()-->Ent3()$
  \item Disjunctive OM query with multiple entity types. $Ent1(...), Ent2(), Ent3(...)$.
  \end{itemize}
  
  
\end{itemize}

\from{HP}{todo:put a figure here to illustrate the steps}.

%Elaborate the first step
The first step is to map the OM concepts in the query to the real data
structure.
With the annotation structures $OT$, $CT$, and $MT$, any given OM
concepts can be linked to a measurement type $mt_{id}$.
Then, the annotation structure $Map$ can be used to bridge OM concepts and data sets.
Utilizing $Map$, we can find the attributes $attr_i$ and the
annotation $A_{id}$).
E.g., when the given concept is {\em measurement}, we can directly get
its related attribute names and annotation id $A_{id}$.
In case that the given OM concept is a non-measurement concept, we can use
other annotation structures to figure out the measurement types.
E.g., if the OM concept is {\em characteristic} ``Species'', we can use
$MT$ to get the measurement type id $mt_{id}$.
After we get $A_{id}$, we can quickly find the dataset id $d_{id}$
using $AD$ metadata table (Section \ref{sec:annotation}).
Then, we get the relevant data tables and the needed attributes.

%Elaborate the second step
Let $D_{cand}$ be the set of relevant (or candidate) data tables and $d_{a_1} \cdots d_{a_m}$
are the related attributes for table $d\in D_{cand}$.


The second step translates the original OM query to SQL queries over the data tables.
From now on, we assume that we know the attribute already for all the needed characteristics. 

To translate the given query:
 Group the basic queries (with only one entity type) to list of context chains. 

\begin{algorithm}[htb]
\begin{algorithmic}[1]
%\begin{footnotesize}
\STATE $Result$ := $\emptyset$; 
\COMMENT{//From the given query, get the DNF of context queries.}
\STATE $contextChainDNF$ := ${\bf GroupBasicQuery}(OMQ)$;
\STATE
\COMMENT{//Execute every DNF int the context chain set and union their results}
\FOR{each context chain $oneContextQuery$ in $contextChainDNF$}
	\STATE $result_{CNF}$ := $\emptyset$;
    \COMMENT{//Execute every basic query in this CNF query and intersect their results}
    \FOR{each basic query $OMBasic$ in $ContextQuery$}
    \STATE $result_{basic}$ := $OMBasic.execute()$;
    \STATE $result_{CNF}$ := $result_{CNF} \cap result_{basic}$;
    \ENDFOR
	\STATE $Result$ := $Result\cup result_{CNF}\$
\ENDFOR
\RETURN $RESULT$;
%\end{footnotesize}
\end{algorithmic}
\caption{Execute(OMQ)}
\label{alg:omq}
\end{algorithm}

\begin{figure}[htb]
%\normalsize
%\begin{minipage}{5in}
%\sf
\begin{scriptsize}
\begin{tabbing}
1166\= 16 \= 16 \= 16 \= 16 \= 16 \= 16 \= 16 \= 16 \= \kill
{\bf Algorithm GroupBasicQuery}($OMQ$);\\
1).\>$contextChainSet$ := $\emptyset$;\\
\\
\>//Put the basic queries in context into context chains
2).\>{\bf for} (each basic context $OMBasic-->ContextOMBasic$ in $OMQ$)\\
3).\>\>$added$ := false;
4).\>\>{\bf for} (each set $oneContextChain \in contextChainDNF)\\
5).\>\>\>{\bf if} (($OMBasic \in oneContextChain$) or $ContextOMBasic \in oneContextChain$))\\
6).\>\>\>\> $oneContextChain$ = $oneContextChain \cup OMBasic \cup ContextOMBasic$\\
7).\>\>\>\> $added$ :=true;\\
8).\>\>\>\> {\bf break;}\\
9).\>\>{\bf if}($added$==false)\\
10).\>\>\>Create a set $newContextChain$ with two elements $OMBasic$ and $ContextOMBasic$;\\
11).\>\>\>Add $newContextChain$ to $contextChainSet$;\\
\\
\>//Put the basic queries in context into context chains
12).\>{\bf for} (each $OMBasic$ not in context of $OMQ$)\\
13).\>\>Create a set $newContextChain$ with one element $OMBasic$\\
14).\>\>Add $newContextChain$ to $contextChainSet$;\\
15).\>{\bf return} $contextChainSet$;\\
\end{tabbing}
\end{scriptsize}
%\end{minipage}
\caption{GroupBasicQuery(OMQ)}
\label{alg:omq}
\end{figure}


In particular, for each candidate data table $d$,
the translation process works in the following rules.

First, for the basic OM query with one entity type. 


Second, for the context chain query. 

\begin{itemize}
\item The SELECT clause always get the distinct $d_{id}$ and/or
  record id $r_{id}$ (when it is needed);
\item The FROM clause has table $d \in D_{cand}$;
\item The WHERE clause contains all the function $f(\cdot)$ in the OM
  query;
\item When there is distinct constraint on entity or observation, the
  GROUP BY clause contains of all the attributes corresponding to the
  {\em key measurement types} of the entity or observation. we detail
  all process of getting the key measurement types of an observation
  later.
\item The aggregation requirement in $f(\cdot)$ is translated to
  HAVING clause.
\end{itemize}

Based on these rules, an OM query can be translated to the following
SQL scripts.

\vspace{0.1in}
{\tt
\begin{tabular}{l}
SELECT DISTINCT $d_{id}$\\
FROM $d$\\
WHERE $f(d_{a_1} \cdots d_{a_m}) = true$\\
$[$GROUP BY {\em distinct requirement}$]$\\
$[$HAVING {\em aggregation condition}$]$;
\end{tabular}
}
\vspace{0.1in}

The above describes the process for the OM query.
In real application, people ask queries with distinct
observation or entity constraints. Also, people ask queries about
different observatitons using context.
The following elaborate the details in processing these two cases.

%In detail,  how to deal with the distinct constraints.
When a query with distinct constraints, e.g., find data sets with {\em distinct} observations or
entities. To deal with this case,
we need to be able to figure out what distinguishes one observation
from another. Here, one observation type's key measurement types can
play this role well.
When an observation type is denoted with {\em distinct yes} and some
of its measurement types are denoted with {\em key yes},
the values of the measurements on the key measurement types can
uniquely distinguish one observation from the other.
To implement this, in SQL, we can perform ``group by'' operations on
the key measurement types of the observations.

%In detail, how to deal with context
When the given OM query has context, we need to consider two cases.
In the first case the context is not {\em identifying} to its
observation types, i.e., the context value
does not affect the uniqueness of one observation, this can be
processed as the basic way.
When the context is denoted with {\em identifying yes}, it means the
identity of one observation also depend on the contextual
observation.
In this case, we need to figure out the all the key measurement types
of one observation, then the ``GROUP BY'' operation should be on all
these key measurement types.
\from{HP}{Put an example here.}
In this case, there is no need to change the SQL scripts.
the only change are the relevant attribute set $d_{a_1} \cdots
d_{a_m}$, which corresponds to not only the measurement types that
directly related to the observation, but also the measurement types
that are in the identifying context chain of the observation.

\from{HP}{Put a specific routine to get key measurements of
  observation and/or entity.}


\begin{example}\label{eg:query_reqerite_q1}
{\bf TODO: refine this example}
Take $Q_1$ ($Observation: \langle Species='Picea~rubens'\rangle$) as
example.
The {\tt OMconcept} is ``observation'' and {\tt cond} is ``{\em species = `Picea rubens'}'';

From the annotation $MT$, we can find the measurement type
$m_3$ with the characteristic {\em species}.
From the mapping $Map$, we further find that the attribute {\em spp} that the
measurement type $m_3$ is mapped to.

The second step is to find the data sets which really have this value.
For this one, we find the data table, and do a selection on the table
content.

\vspace{0.1in}
{\tt
\begin{tabular}{l}
SELECT DISTINCT $d_{id}$\\
FROM $d$\\
WHERE $spp = 'piru'$
\end{tabular}
}
\vspace{0.1in}

\end{example}

\begin{example}
Take $Q_3$ ($Observation:$\\
$\langle Species='Picea~rubens'$$\wedge count(distinct~Species)\geq
5\rangle$) as an example.

\from{HP}{Refine\\
For the first step, we find the data tables that contain the needed concepts.
In each table, we need to figure out the distinct observations.
From $m_i$ $obstype_i$, all the other measurements that are of
$obstype_i$.
Group by the key measurements of $obstype_i$ if distinct yes.
If this observation type does not have any context, then the key
measurements are all the measurements directly defined under this
observatioin type. Otherwise, i.e., this observation type has context,
then the key measurements are all the measurements in the context
chain. }

\vspace{0.1in}
{\tt
\begin{tabular}{l}
SELECT DISTINCT $d_{id}$\\
FROM $d$\\
WHERE $spp = 'piru'$\\
GROUP BY $d_{id}$, $spp$\\
HAVING count($d_{id}$,$spp$) $\geq 5$\\
\end{tabular}
}
\vspace{0.1in}

\end{example}

%Analysis of this method.
{\bf Cost analysis:}
From the above description, we can tell that the computation cost is to search the different data
tables. This way, for each candidate data table, we need to send an
SQL query to the server for evaluation purpose.
If the number of candidate data tables are small. This method should
work well. However, when we have a lot of candidate data tables, the
efficiency may be affected.
In what follows, we introduce another strategy, which logically merge
the data content in different tables and perform queries ober the
materialized database.

\subsection{Querying materialized database}\label{sec:matdb}

The previous section shows the method to rewrite a given query.
However, as we analyzed, the computation cost may be very high when
there are many candidate data tables.
In this section, we propose another strategy to answer the given OM
query by making use of the existing optimization strategies of
current DBMS.

%rough idea of this strategy
In this strategy, we do not directly work on the original data table
$D$. On the other hand, we {\em materialize} the original data-sets to
centralized concept tables with instances of entities, observations, measurements
and contexts. Such concept tables are called core OBOE tables, and denoted as
$OBOE.*$.
Then, the query process works on the materialized databases (i.e., the
conceptual data tables).

%structure of this sub-section
In what follows, we first describe the structure of the core
conceptual tables and present our algorithm to materialize the data into such
concept instance tables in Section \ref{sec:materialilzedb}. Our
algorithm considers all the distinct and context constraints.
Then, Section \ref{sec:query_materialilzedb} provides the detailed
process of performing queries over materialized database.

\subsubsection{Materialize data}\label{sec:materialilzedb}

%Structure of conceptual instances
In particular, we have the following concept instance tables.
\begin{itemize}
%\item $EI$ = $\{(\underline{ei_{id}}, et_{id})\}$ for all the entity instances;
\item $OI$ = $\{(\underline{oi_{id}}, ot_{id}, ei_{id})\}$ keeps
  all the observation instances where $ot_{id}$ is used to link to the
  annotation information in $OT$;
\item $MI$ = $\{(\underline{mi_{id}}, oi_{id}, mt_{id},
  mVal)\}$ for all the measurement instances where $mt_{id}$ is used to link to the
  annotation information in $MT$;
\item $CI =\{(\underline{oi_{id},coi_{id},ct_{id}})\}$ for
  all the context instances where $ct_{id}$ is used to link to the
  annotation information in $CT$.
\end{itemize}

\from{HP}{TODO: refine the writing in MaterializeDB and move them here.}

\subsubsection{Querying materialized database}\label{sec:query_materialilzedb}

Once the data are materialized using the annotation constraints, we
can perform the OM query over them.
%In what follows, we describe how to use the materialized data to answer the query.

\from{HP}{TODO:Formalize the translation of operators in the OM
  query}.

When the given query is a basic OM query, i.e., there is not context
in the query.
Then, we can form a template query as the following;

\begin{figure}[htb]
{\tt
\begin{tabular}{l}
SELECT $[$DISTINCT$]$ $AD.d_{id}$\\
FROM $AD, MI~as~mi, MT~as~mt[$, {\em other tables}$]$\\
$[$WHERE    {\em table join condition}, \\
$\qquad\qquad$ AND {\em selection condition}$]$,\\
$[$GROUP BY {\em distinct requirement} $]$\\
$[$HAVING   {\em aggregation condition} $]$;
\end{tabular}
}
\caption{SQL template to answer OM using materialized DB}
\label{fig:sql_matdb_basic_omq}
\end{figure}

In particular,

\vspace{0.1in}
\begin{tabular}{l}
$table~join~condition=$\\
%$\qquad (mi.oi_{id}=ci.oi_{id})~AND~(cmi.oi_{id}=ci.coi_{id})~AND$\\
$\qquad (mi.mt_{id}=mt.mt_{id})~AND~(mt.A_{id}=AD.A_{id})$
\end{tabular}
\vspace{0.1in}

For the very basic query (e.g., $Q_1$ in Example \ref{eg:query}), the
SQL generally need only the first three clauses.
If the query has some restriction on the aggregated result, the {\tt
  GROUP BY} and {\tt HAVING} clauses to deal with it.

We use $Q_1$ and $Q_3$ to illustrate the query on the materialized
database.
can be answered using the above
template.
Example \ref{eg:query_reqerite_q1} shows how to deal with $Q_1$ using
the query rewriting method.

\begin{example} \label{eg:materialize_db_q1}
Using the  materialized database,  we just need to search the MI table
with the condition that {\em mVal=``Picea rubens''}.

\vspace{0.1in}
{\tt
\begin{tabular}{l}
SELECT DISTINCT $AD.d_{id}$\\
FROM $AD, MI~as~mi, MT~as~mt$\\
WHERE $mt.Cha='Species'$ \\
$\qquad\quad$ AND $mi.mVal = `Picea~rubens'$\\
$\qquad\quad$ AND $mi.mt_{id}=mt.mt_{id}$\\
$\qquad\quad$ AND $mi.A_{id}=AD.A_{id}$;
%\#Join the MI and MT tables
\end{tabular}
}
\vspace{0.1in}

For $Q_3$, which asks for data sets that contain at
least five distinct ``Picea rubens'' observations.
The SQL query can be written as:

\vspace{0.1in}
{\tt
\begin{tabular}{l}
SELECT distinct $AD.d_{id}$\\
FROM $AD, MI~as~mi, MT~as~mt$\\
WHERE $mt.Cha='Species'$ \\
$\qquad\quad$ AND $mi.mVal = `Picea~rubens'$\\
$\qquad\quad$ AND $mi.mt_{id}=mt.mt_{id}$\\
$\qquad\quad$ AND $mt.A_{id}=AD.A_{id}$\\
GROUP BY $d_{id},oi_{id}$\\
HAVING COUNT(*)$>$5;
\end{tabular}
}
\vspace{0.1in}
\end{example}

For this kind of query, the computation cost is the selection cost of the
measurement instance (MI) table.
Compared with the query rewriting strategy, which need to pose the
query over multiple data tables, this query should answer the queries
more efficiently.

Figure \ref{fig:sql_matdb_basic_omq} shows the SQL template to process
the basic OM query without context. In case the OM query has context,
we need to add the context into consideration.

\begin{enumerate}
\item The first step is similar to that in the basic OM query
  processing. Besides this, we need to figure out what are the concept
  obserbationi types of the needed observations.
\item \label{step:singlesql} Form an SQL for the observation and every of its context
  observations.
\item Intersect all the SQLs from Step \ref{step:singlesql}).
\end{enumerate}


\begin{figure}[htb]
{\tt
\begin{tabular}{l}
SELECT $[$DISTINCT$]$ $AD.d_{id}$\\
FROM $AD, CI~as~ci,MI~as~mi, MT~as~mt$\\
$\qquad MI~as~cmi, MT~as~cmt[,$ {\em other tables}$]$\\
$[$WHERE    {\em table join condition}, \\
$\qquad\qquad$ AND {\em selection condition}$]$,\\
$[$GROUP BY {\em distinct requirement} $]$\\
$[$HAVING   {\em aggregation condition} $]$;
\end{tabular}
}
\caption{SQL template to answer contextualized OM using materialized DB}
\label{fig:sql_matdb_context_omq}
\end{figure}

In this case, the table join condition is much more complex since we
need to use the context instance table $ci$ to connect the
observation and context observation table.
In particular,

\vspace{0.1in}
{\tt
\begin{tabular}{l}
$table~join~condition=$\\
$\qquad (mi.oi_{id}=ci.oi_{id})$ AND $(cmi.oi_{id}=ci.coi_{id})$ AND\\
$\qquad (mi.mt_{id}=mt.mt_{id})$ AND $(cmi.mt_{id}=cmt.mt_{id})$ AND\\
$\qquad (mt.A_{id}=AD.A_{id})$
\end{tabular}
}
\vspace{0.1in}

{\bf Execution cost analysis:} From the join condition, we can see that the expensive cost comes from
the join operation between the measurement instance, context
measurement instance, and context instance table.
As we analyzed in Section \ref{sec:materialilzedb}, the two tables with
growing space are measurement instance table and context instance
table.

{\bf Example:} When we are given contextualized query, e.g., $Q_2$, which asks for
the datasets that contain species ``Picea rubens'' observations in
``California''.

In the first step, we get the requirement is on Characteristic
``Species'' with value ($mVal$) ``Picea rubens'' and observation has context {\em in}
another observation for ``State'' of value ``California''.


%Using materializedDB, we can answer the query this way
%First, from the Characteristic ``Species'', we can get  --> mlabel, observation type

%select mtype, olabel from measurement\_type  \\
%where chracteristic = 'Species';  \\
In the first step, we need to find the context type id $tmp\_ct\_id$
that satisfy the context relationship.

{\tt
\begin{tabular}{l}
SELECT $ct.ct_{id} as tmp\_ct\_id$\\
FROM OT as ot, OT as cot, CT as ct\\
WHERE $ct.ot_{id} = ot.ot_{id}$ AND \\
      $\qquad ct.cot_{id}= cot.ot_{id}$ AND \\
      $\qquad ct.Rel='IN'$ AND $ot.et='tree'$;
\end{tabular}
}

Then, the next step is to find the distinct data sets.

\vspace{0.1in}
{\tt
\begin{tabular}{l}
SELECT DISTINCT $AD.d_{id}$\\
FROM $AD, CI~as~ci, MI~as~mi, MT~as~mt,$ \\
$\quad\qquad MI~as~cmi, MT~as~cmt,$ \\
WHERE $(mi.oi_{id}=ci.oi_{id})$ AND $(cmi.oi_{id}=ci.coi_{id})$ AND\\
$\qquad (mi.mt_{id}=mt.mt_{id})$ AND $(cmi.mt_{id}=cmt.mt_{id})$ AND\\
$\qquad (mt.A_{id}=AD.A_{id})$\\
$\qquad$ AND $mi.mVal=`Picea rubens'$ \\
$\qquad$ AND $cmi.mVal='California'$\\
$\qquad$ AND $mt.Cha = 'Species'$\\
$\qquad$ AND $cmt.Cha=`State'$\\
$\qquad$ AND $ci.ct_{id} = tmp\_ct\_id)$\\
\end{tabular}
}
\vspace{0.1in}


%Use query rewriting, what I can do?
%It's the same till to getting context\_olabel\_set.

%Get the asked condition columns and the context columns,

%select record\_id from data\_tables
%where condition column 1='value1' and (context column1 = 'context
%value' or context column2 = `context value', etc.);

Now let's think about the query $Q_4$ with aggregation and context
requirement.
% Give me the data sets that have trees with average ``height''
%  than 20.0 in ``California''.
$Q_4 = Observation_1: \langle avg(distinct~tree.height)\geq 20.0 \rangle$
$\wedge IN(Observation_1, Observation_2)$\\
$\wedge Observation_2: \langle State='California'\rangle$


Also, in the first step, we discover the context type id $tmp\_ct\_id$
that satisfy the context relationship.


\vspace{0.1in}
{\tt
\begin{tabular}{l}
SELECT DISTINCT $AD.d_{id}$ \\
FROM $AD, CI~as~ci, MI~as~mi, MI~as~cmi,$ \\
$\quad\qquad MT~as~mt, MT~as~cmt,$ \\
WHERE $(mi.oi_{id}=ci.oi_{id})$ AND $(cmi.oi_{id}=ci.coi_{id})$ AND\\
$\qquad (mi.mt_{id}=mt.mt_{id})$ AND $(cmi.mt_{id}=cmt.mt_{id})$ AND\\
$\qquad (mt.A_{id}=AD.A_{id})$\\
$\qquad$ AND $mt.Cha=`height'$\\
$\qquad$ AND $cmt.Cha=`State'$\\
$\qquad$ AND $cmi.mVal=`California'$\\
$\qquad$ AND $ci.ct_{id} = tmp\_ct\_id)$\\
GROUP BY $AD.d_{id}, oi_{id}$\\
HAVING $avg(mi.mVal)>5.0$;
\end{tabular}
}
\vspace{0.1in}

Note that, in the above example, there is only one context.
In the real application, there may be multiple context observations,
or even context chains. In this case, we need to get {\em all} the
context and get the intersection of the results.


\subsection{Query partially materialized database}
As we analyzed in the first two sub-sections,
the query-rewriting suffers the multiple queries posed on different
candidate dataset. The querying of materialized database suffers from
the multiple self-join operation of the measurement instance (MI)
table, which has the most amount of information.

In this section, we propose to materialize only the measurement
instance and also put the measurement instance and context measurement
instances together in the same table to avoid the expensive
computation cost.

\from{HP}{Let's see how this can work. } 